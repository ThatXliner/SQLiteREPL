#!/usr/bin/env python
# -*- coding: utf-8 -*-

# AIM: index the whole file system starting from 'starting_location'
#
# Row[name: str,
#     mode: int,
#     inode: int,
#     device: int,
#     nlinks: int,
#     uid: int,
#     gid: int,
#     size: int,
#     atime: int,
#     mtime: int,
#     ctime: int]

import os
from typing import List, Tuple, Union, Iterable
from itertools import starmap
from functools import reduce
import operator

import sqlite3

from db import SQLite
from argparse import ArgumentParser, Namespace

Entry = Tuple[Union[str, float, None, int], ...]

parser: ArgumentParser = ArgumentParser()

parser.add_argument('-d', '--database_location', default='~/.sqlite')

parser.add_argument('-s', '--starting_location', default='~')

args: Namespace = parser.parse_args()

db_path: str = os.path.expanduser(args.database_location)

starting_location: str = os.path.expanduser(args.starting_location)

cols: List[str] = [
    "name", "mode", "inode",
    "device", "nlinks",
    "uid", "gid", "size",
    "atime", "mtime", "ctime"]

# necessary as DataFrames print in the reverse order
cols.reverse()

cols = tuple(cols)

raw: List[Tuple[Union[str, int]]] = os.walk(starting_location)

# lists
data: Iterable[List[Union[str, int]]] = starmap(
    lambda dirpath, dirnames, filenames: [dirpath] + [os.path.join(dirpath, f) for f in filenames],
    raw)

# flattened to 1 level
data: List[str] = reduce(operator.add, data)

# filtered to files
data: Iterable[str] = filter(os.path.isfile, data)

# stats
rows: List[Entry] = list(map(lambda f: os.stat(f) + tuple([f]), data))

db: SQLite = SQLite()

try:
    db.query('DROP TABLE files;')
except sqlite3.Error as e:
    pass

db.query(
    'CREATE TABLE files (name TEXT, mode INTEGER, inode INTEGER, device INTEGER , nlinks INTEGER, uid INTEGER, '
    'gid INTEGER, size INTEGER, atime INTEGER, mtime INTEGER, ctime INTEGER)')

for col in cols:
    db.query('INSERT INTO files VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)', col)

db.close_connection()
# vim: ft=python
